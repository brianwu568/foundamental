# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

import typing
import typing_extensions
import baml_py

from . import stream_types, types, type_builder
from .parser import LlmResponseParser, LlmStreamParser
from .runtime import DoNotUseDirectlyCallManager, BamlCallOptions
from .globals import DO_NOT_USE_DIRECTLY_UNLESS_YOU_KNOW_WHAT_YOURE_DOING_RUNTIME as __runtime__


class BamlAsyncClient:
    __options: DoNotUseDirectlyCallManager
    __stream_client: "BamlStreamClient"
    __http_request: "BamlHttpRequestClient"
    __http_stream_request: "BamlHttpStreamRequestClient"
    __llm_response_parser: LlmResponseParser
    __llm_stream_parser: LlmStreamParser

    def __init__(self, options: DoNotUseDirectlyCallManager):
        self.__options = options
        self.__stream_client = BamlStreamClient(options)
        self.__http_request = BamlHttpRequestClient(options)
        self.__http_stream_request = BamlHttpStreamRequestClient(options)
        self.__llm_response_parser = LlmResponseParser(options)
        self.__llm_stream_parser = LlmStreamParser(options)

    def with_options(self,
        tb: typing.Optional[type_builder.TypeBuilder] = None,
        client_registry: typing.Optional[baml_py.baml_py.ClientRegistry] = None,
        collector: typing.Optional[typing.Union[baml_py.baml_py.Collector, typing.List[baml_py.baml_py.Collector]]] = None,
        env: typing.Optional[typing.Dict[str, typing.Optional[str]]] = None,
        tags: typing.Optional[typing.Dict[str, str]] = None,
        on_tick: typing.Optional[typing.Callable[[str, baml_py.baml_py.FunctionLog], None]] = None,
    ) -> "BamlAsyncClient":
        options: BamlCallOptions = {}
        if tb is not None:
            options["tb"] = tb
        if client_registry is not None:
            options["client_registry"] = client_registry
        if collector is not None:
            options["collector"] = collector
        if env is not None:
            options["env"] = env
        if tags is not None:
            options["tags"] = tags
        if on_tick is not None:
            options["on_tick"] = on_tick
        return BamlAsyncClient(self.__options.merge_options(options))

    @property
    def stream(self):
      return self.__stream_client

    @property
    def request(self):
      return self.__http_request

    @property
    def stream_request(self):
      return self.__http_stream_request

    @property
    def parse(self):
      return self.__llm_response_parser

    @property
    def parse_stream(self):
      return self.__llm_stream_parser
    
    async def BrandSentiment(self, brand: str,passage: str,
        baml_options: BamlCallOptions = {},
    ) -> types.SentimentResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.BrandSentiment(brand=brand,passage=passage,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="BrandSentiment", args={
                "brand": brand,"passage": passage,
            })
            return typing.cast(types.SentimentResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def EvalBrandMatch(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> types.BrandMatchResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.EvalBrandMatch(text=text,brand_name=brand_name,brand_aliases=brand_aliases,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="EvalBrandMatch", args={
                "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
            })
            return typing.cast(types.BrandMatchResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def EvalBrandMatchBatch(self, text: str,brands: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> types.BrandMatchBatchResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.EvalBrandMatchBatch(text=text,brands=brands,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="EvalBrandMatchBatch", args={
                "text": text,"brands": brands,
            })
            return typing.cast(types.BrandMatchBatchResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def EvalBrandMatchOllama(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> types.BrandMatchResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.EvalBrandMatchOllama(text=text,brand_name=brand_name,brand_aliases=brand_aliases,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="EvalBrandMatchOllama", args={
                "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
            })
            return typing.cast(types.BrandMatchResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def EvalOutput(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> types.EvalResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.EvalOutput(expected=expected,actual=actual,criteria=criteria,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="EvalOutput", args={
                "expected": expected,"actual": actual,"criteria": criteria,
            })
            return typing.cast(types.EvalResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def EvalOutputOllama(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> types.EvalResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.EvalOutputOllama(expected=expected,actual=actual,criteria=criteria,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="EvalOutputOllama", args={
                "expected": expected,"actual": actual,"criteria": criteria,
            })
            return typing.cast(types.EvalResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def ExtractResume(self, resume: str,
        baml_options: BamlCallOptions = {},
    ) -> types.Resume:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.ExtractResume(resume=resume,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="ExtractResume", args={
                "resume": resume,
            })
            return typing.cast(types.Resume, result.cast_to(types, types, stream_types, False, __runtime__))
    async def RankEntities(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> types.RankingResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.RankEntities(query=query,k=k,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="RankEntities", args={
                "query": query,"k": k,
            })
            return typing.cast(types.RankingResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def RankEntitiesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> types.RankingResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.RankEntitiesOllama(query=query,k=k,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="RankEntitiesOllama", args={
                "query": query,"k": k,
            })
            return typing.cast(types.RankingResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def RankEntitiesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> types.RankingResult:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.RankEntitiesOpenAI(query=query,k=k,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="RankEntitiesOpenAI", args={
                "query": query,"k": k,
            })
            return typing.cast(types.RankingResult, result.cast_to(types, types, stream_types, False, __runtime__))
    async def RankEntitiesWithSourcesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> types.RankingResultWithSources:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.RankEntitiesWithSourcesOllama(query=query,k=k,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="RankEntitiesWithSourcesOllama", args={
                "query": query,"k": k,
            })
            return typing.cast(types.RankingResultWithSources, result.cast_to(types, types, stream_types, False, __runtime__))
    async def RankEntitiesWithSourcesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> types.RankingResultWithSources:
        # Check if on_tick is provided
        if 'on_tick' in baml_options:
            # Use streaming internally when on_tick is provided
            stream = self.stream.RankEntitiesWithSourcesOpenAI(query=query,k=k,
                baml_options=baml_options)
            return await stream.get_final_response()
        else:
            # Original non-streaming code
            result = await self.__options.merge_options(baml_options).call_function_async(function_name="RankEntitiesWithSourcesOpenAI", args={
                "query": query,"k": k,
            })
            return typing.cast(types.RankingResultWithSources, result.cast_to(types, types, stream_types, False, __runtime__))
    


class BamlStreamClient:
    __options: DoNotUseDirectlyCallManager

    def __init__(self, options: DoNotUseDirectlyCallManager):
        self.__options = options

    def BrandSentiment(self, brand: str,passage: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.SentimentResult, types.SentimentResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="BrandSentiment", args={
            "brand": brand,"passage": passage,
        })
        return baml_py.BamlStream[stream_types.SentimentResult, types.SentimentResult](
          result,
          lambda x: typing.cast(stream_types.SentimentResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.SentimentResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def EvalBrandMatch(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.BrandMatchResult, types.BrandMatchResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="EvalBrandMatch", args={
            "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
        })
        return baml_py.BamlStream[stream_types.BrandMatchResult, types.BrandMatchResult](
          result,
          lambda x: typing.cast(stream_types.BrandMatchResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.BrandMatchResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def EvalBrandMatchBatch(self, text: str,brands: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.BrandMatchBatchResult, types.BrandMatchBatchResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="EvalBrandMatchBatch", args={
            "text": text,"brands": brands,
        })
        return baml_py.BamlStream[stream_types.BrandMatchBatchResult, types.BrandMatchBatchResult](
          result,
          lambda x: typing.cast(stream_types.BrandMatchBatchResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.BrandMatchBatchResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def EvalBrandMatchOllama(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.BrandMatchResult, types.BrandMatchResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="EvalBrandMatchOllama", args={
            "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
        })
        return baml_py.BamlStream[stream_types.BrandMatchResult, types.BrandMatchResult](
          result,
          lambda x: typing.cast(stream_types.BrandMatchResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.BrandMatchResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def EvalOutput(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.EvalResult, types.EvalResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="EvalOutput", args={
            "expected": expected,"actual": actual,"criteria": criteria,
        })
        return baml_py.BamlStream[stream_types.EvalResult, types.EvalResult](
          result,
          lambda x: typing.cast(stream_types.EvalResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.EvalResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def EvalOutputOllama(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.EvalResult, types.EvalResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="EvalOutputOllama", args={
            "expected": expected,"actual": actual,"criteria": criteria,
        })
        return baml_py.BamlStream[stream_types.EvalResult, types.EvalResult](
          result,
          lambda x: typing.cast(stream_types.EvalResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.EvalResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def ExtractResume(self, resume: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.Resume, types.Resume]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="ExtractResume", args={
            "resume": resume,
        })
        return baml_py.BamlStream[stream_types.Resume, types.Resume](
          result,
          lambda x: typing.cast(stream_types.Resume, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.Resume, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def RankEntities(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.RankingResult, types.RankingResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="RankEntities", args={
            "query": query,"k": k,
        })
        return baml_py.BamlStream[stream_types.RankingResult, types.RankingResult](
          result,
          lambda x: typing.cast(stream_types.RankingResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.RankingResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def RankEntitiesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.RankingResult, types.RankingResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="RankEntitiesOllama", args={
            "query": query,"k": k,
        })
        return baml_py.BamlStream[stream_types.RankingResult, types.RankingResult](
          result,
          lambda x: typing.cast(stream_types.RankingResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.RankingResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def RankEntitiesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.RankingResult, types.RankingResult]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="RankEntitiesOpenAI", args={
            "query": query,"k": k,
        })
        return baml_py.BamlStream[stream_types.RankingResult, types.RankingResult](
          result,
          lambda x: typing.cast(stream_types.RankingResult, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.RankingResult, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def RankEntitiesWithSourcesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.RankingResultWithSources, types.RankingResultWithSources]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="RankEntitiesWithSourcesOllama", args={
            "query": query,"k": k,
        })
        return baml_py.BamlStream[stream_types.RankingResultWithSources, types.RankingResultWithSources](
          result,
          lambda x: typing.cast(stream_types.RankingResultWithSources, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.RankingResultWithSources, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    def RankEntitiesWithSourcesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.BamlStream[stream_types.RankingResultWithSources, types.RankingResultWithSources]:
        ctx, result = self.__options.merge_options(baml_options).create_async_stream(function_name="RankEntitiesWithSourcesOpenAI", args={
            "query": query,"k": k,
        })
        return baml_py.BamlStream[stream_types.RankingResultWithSources, types.RankingResultWithSources](
          result,
          lambda x: typing.cast(stream_types.RankingResultWithSources, x.cast_to(types, types, stream_types, True, __runtime__)),
          lambda x: typing.cast(types.RankingResultWithSources, x.cast_to(types, types, stream_types, False, __runtime__)),
          ctx,
        )
    

class BamlHttpRequestClient:
    __options: DoNotUseDirectlyCallManager

    def __init__(self, options: DoNotUseDirectlyCallManager):
        self.__options = options

    async def BrandSentiment(self, brand: str,passage: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="BrandSentiment", args={
            "brand": brand,"passage": passage,
        }, mode="request")
        return result
    async def EvalBrandMatch(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalBrandMatch", args={
            "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
        }, mode="request")
        return result
    async def EvalBrandMatchBatch(self, text: str,brands: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalBrandMatchBatch", args={
            "text": text,"brands": brands,
        }, mode="request")
        return result
    async def EvalBrandMatchOllama(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalBrandMatchOllama", args={
            "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
        }, mode="request")
        return result
    async def EvalOutput(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalOutput", args={
            "expected": expected,"actual": actual,"criteria": criteria,
        }, mode="request")
        return result
    async def EvalOutputOllama(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalOutputOllama", args={
            "expected": expected,"actual": actual,"criteria": criteria,
        }, mode="request")
        return result
    async def ExtractResume(self, resume: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="ExtractResume", args={
            "resume": resume,
        }, mode="request")
        return result
    async def RankEntities(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntities", args={
            "query": query,"k": k,
        }, mode="request")
        return result
    async def RankEntitiesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesOllama", args={
            "query": query,"k": k,
        }, mode="request")
        return result
    async def RankEntitiesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesOpenAI", args={
            "query": query,"k": k,
        }, mode="request")
        return result
    async def RankEntitiesWithSourcesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesWithSourcesOllama", args={
            "query": query,"k": k,
        }, mode="request")
        return result
    async def RankEntitiesWithSourcesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesWithSourcesOpenAI", args={
            "query": query,"k": k,
        }, mode="request")
        return result
    

class BamlHttpStreamRequestClient:
    __options: DoNotUseDirectlyCallManager

    def __init__(self, options: DoNotUseDirectlyCallManager):
        self.__options = options

    async def BrandSentiment(self, brand: str,passage: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="BrandSentiment", args={
            "brand": brand,"passage": passage,
        }, mode="stream")
        return result
    async def EvalBrandMatch(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalBrandMatch", args={
            "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
        }, mode="stream")
        return result
    async def EvalBrandMatchBatch(self, text: str,brands: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalBrandMatchBatch", args={
            "text": text,"brands": brands,
        }, mode="stream")
        return result
    async def EvalBrandMatchOllama(self, text: str,brand_name: str,brand_aliases: typing.List[str],
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalBrandMatchOllama", args={
            "text": text,"brand_name": brand_name,"brand_aliases": brand_aliases,
        }, mode="stream")
        return result
    async def EvalOutput(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalOutput", args={
            "expected": expected,"actual": actual,"criteria": criteria,
        }, mode="stream")
        return result
    async def EvalOutputOllama(self, expected: str,actual: str,criteria: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="EvalOutputOllama", args={
            "expected": expected,"actual": actual,"criteria": criteria,
        }, mode="stream")
        return result
    async def ExtractResume(self, resume: str,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="ExtractResume", args={
            "resume": resume,
        }, mode="stream")
        return result
    async def RankEntities(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntities", args={
            "query": query,"k": k,
        }, mode="stream")
        return result
    async def RankEntitiesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesOllama", args={
            "query": query,"k": k,
        }, mode="stream")
        return result
    async def RankEntitiesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesOpenAI", args={
            "query": query,"k": k,
        }, mode="stream")
        return result
    async def RankEntitiesWithSourcesOllama(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesWithSourcesOllama", args={
            "query": query,"k": k,
        }, mode="stream")
        return result
    async def RankEntitiesWithSourcesOpenAI(self, query: str,k: int,
        baml_options: BamlCallOptions = {},
    ) -> baml_py.baml_py.HTTPRequest:
        result = await self.__options.merge_options(baml_options).create_http_request_async(function_name="RankEntitiesWithSourcesOpenAI", args={
            "query": query,"k": k,
        }, mode="stream")
        return result
    

b = BamlAsyncClient(DoNotUseDirectlyCallManager({}))